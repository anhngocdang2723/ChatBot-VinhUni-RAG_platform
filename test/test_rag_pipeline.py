"""
Test script for complete RAG pipeline: Pinecone retrieval + Qwen3-Max generation
"""
import os
import sys
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

print("="*70)
print("TEST: Complete RAG Pipeline (Pinecone + Qwen3-Max)")
print("="*70)

# Test 1: Check environment variables
print("\n[1/5] Checking environment variables...")
required_vars = ["PINECONE_API_KEY", "DASHSCOPE_API_KEY", "SECRET_KEY"]
for var in required_vars:
    value = os.getenv(var)
    if value:
        masked = f"{value[:8]}...{value[-4:]}" if len(value) > 12 else "***"
        print(f"  ‚úÖ {var}: {masked}")
    else:
        print(f"  ‚ùå {var}: NOT SET")
        sys.exit(1)

print("\n‚úÖ All required environment variables are set")

# Test 2: Import services
print("\n[2/5] Importing services...")
try:
    from core.pinecone.pinecone_service import PineconeService
    from core.llm.llm_interface import RAGPromptManager, create_llm_provider
    print("‚úÖ Successfully imported PineconeService and RAGPromptManager")
except ImportError as e:
    print(f"‚ùå Failed to import: {str(e)}")
    sys.exit(1)

# Test 3: Initialize services
print("\n[3/5] Initializing services...")
try:
    # Initialize Pinecone service
    pinecone_api_key = os.getenv("PINECONE_API_KEY")
    dashscope_api_key = os.getenv("DASHSCOPE_API_KEY")
    
    if not pinecone_api_key or not dashscope_api_key:
        raise ValueError("Missing required API keys")
    
    pinecone_service = PineconeService(
        api_key=pinecone_api_key,
        environment="us-east-1"
    )
    print("‚úÖ Pinecone service initialized")
    print(f"   Dense index: {pinecone_service.dense_index_name}")
    print(f"   Sparse index: {pinecone_service.sparse_index_name}")
    
    # Initialize LLM service
    provider = create_llm_provider("qwen", dashscope_api_key)
    llm_service = RAGPromptManager(provider=provider)
    print("‚úÖ Qwen3-Max LLM service initialized")
    
except Exception as e:
    print(f"‚ùå Failed to initialize services: {str(e)}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 4: Setup indexes and upsert test documents
print("\n[4/5] Setting up Pinecone indexes with test data...")
try:
    # Setup indexes
    pinecone_service.setup_indexes()
    print("‚úÖ Indexes setup complete")
    
    # Check if test documents already exist
    if pinecone_service.dense_index:
        dense_stats = pinecone_service.dense_index.describe_index_stats()
        dense_count = dense_stats.get('total_vector_count', 0)
    else:
        dense_count = 0
    
    print(f"   Dense index vectors: {dense_count}")
    
    # Upsert test documents if not already present
    if dense_count == 0 or dense_count < 3:
        print("   Upserting test documents...")
        test_documents = [
            {
                "id": "rag_test_1",
                "text": "Tr∆∞·ªùng ƒê·∫°i h·ªçc Vinh ƒë∆∞·ª£c th√†nh l·∫≠p nƒÉm 1959, l√† m·ªôt trong nh·ªØng tr∆∞·ªùng ƒë·∫°i h·ªçc l√¢u ƒë·ªùi v√† uy t√≠n nh·∫•t Vi·ªát Nam. Tr∆∞·ªùng c√≥ truy·ªÅn th·ªëng ƒë√†o t·∫°o ch·∫•t l∆∞·ª£ng cao.",
                "metadata": {
                    "source": "test",
                    "document_type": "text",
                    "is_test": "true"
                }
            },
            {
                "id": "rag_test_2",
                "text": "ƒê·∫°i h·ªçc Vinh c√≥ nhi·ªÅu khoa nh∆∞ Khoa C√¥ng ngh·ªá Th√¥ng tin, Khoa To√°n, Khoa V·∫≠t l√Ω, Khoa H√≥a h·ªçc, Khoa Sinh h·ªçc. M·ªói khoa c√≥ ƒë·ªôi ng≈© gi·∫£ng vi√™n gi√†u kinh nghi·ªám.",
                "metadata": {
                    "source": "test",
                    "document_type": "text",
                    "is_test": "true"
                }
            },
            {
                "id": "rag_test_3",
                "text": "Sinh vi√™n ƒê·∫°i h·ªçc Vinh ƒë∆∞·ª£c ƒë√†o t·∫°o theo ch∆∞∆°ng tr√¨nh chu·∫©n qu·ªëc t·∫ø v·ªõi nhi·ªÅu c∆° h·ªôi th·ª±c t·∫≠p v√† nghi√™n c·ª©u khoa h·ªçc. Tr∆∞·ªùng c√≥ h·ª£p t√°c v·ªõi nhi·ªÅu ƒë·∫°i h·ªçc n·ªïi ti·∫øng tr√™n th·∫ø gi·ªõi.",
                "metadata": {
                    "source": "test",
                    "document_type": "text",
                    "is_test": "true"
                }
            }
        ]
        
        pinecone_service.upsert_documents(
            documents=test_documents,
            namespace="test"
        )
        print("‚úÖ Test documents uploaded")
        print("   Waiting 2 seconds for indexing...")
        import time
        time.sleep(2)
    else:
        print("   Test documents already exist")
    
except Exception as e:
    print(f"‚ùå Failed to setup indexes: {str(e)}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Test 5: Test complete RAG pipeline
print("\n[5/5] Testing complete RAG pipeline (Retrieve + Generate)...")
print("="*70)

test_queries = [
    "ƒê·∫°i h·ªçc Vinh th√†nh l·∫≠p nƒÉm nao?",
    "ƒê·∫°i h·ªçc Vinh c√≥ nh·ªØng khoa n√†o?",
    "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o c·ªßa ƒê·∫°i h·ªçc Vinh nh∆∞ th·∫ø n√†o?"
]

try:
    for i, query in enumerate(test_queries, 1):
        print(f"\nüìù Query {i}: {query}")
        print("-" * 70)
        
        # Step 1: Retrieve relevant documents
        print("   üîç Step 1: Retrieving documents from Pinecone...")
        search_results = pinecone_service.hybrid_search(
            query=query,
            namespace="test",
            top_k=2
        )
        
        if not search_results:
            print("   ‚ö†Ô∏è  No documents retrieved")
            continue
        
        print(f"   ‚úÖ Retrieved {len(search_results)} documents:")
        for j, result in enumerate(search_results, 1):
            score = result.get('_score', 0)
            fields = result.get('fields', {})
            text = fields.get('chunk_text', '')
            text_preview = text[:60] + "..." if len(text) > 60 else text
            print(f"      {j}. Score: {score:.4f} - {text_preview}")
        
        # Step 2: Prepare documents for LLM
        documents = []
        for result in search_results:
            fields = result.get('fields', {})
            documents.append({
                'text': fields.get('chunk_text', ''),
                'metadata': {
                    'source': fields.get('source', 'unknown'),
                    'document_type': fields.get('document_type', 'text')
                },
                'score': result.get('_score', 0)
            })
        
        # Step 3: Generate answer with Qwen
        # Note: qwen-turbo is available in free tier
        print("\n   ü§ñ Step 2: Generating answer with Qwen-Turbo...")
        response = llm_service.generate_answer(
            query=query,
            documents=documents,
            temperature=0.7,
            max_tokens=300,
            model="qwen3-max"
        )
        
        print("\n   ‚úÖ Generated Answer:")
        print("   " + "‚îÄ" * 66)
        # Format answer with proper indentation
        answer_lines = response['answer'].split('\n')
        for line in answer_lines:
            print(f"   {line}")
        print("   " + "‚îÄ" * 66)
        
        print(f"\n   üìö Sources: {len(response['sources'])} documents used")
        
except Exception as e:
    print(f"\n‚ùå RAG pipeline failed: {str(e)}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Summary
print("\n" + "="*70)
print("TEST SUMMARY")
print("="*70)
print("‚úÖ Environment variables: OK")
print("‚úÖ Services initialization: OK")
print("‚úÖ Pinecone retrieval: OK")
print("‚úÖ Qwen3-Max generation: OK")
print("‚úÖ Complete RAG pipeline: OK")
print("\nüéâ All tests passed! RAG pipeline is working correctly!")
print("\nNote: Test documents in 'test' namespace")
print("="*70)
